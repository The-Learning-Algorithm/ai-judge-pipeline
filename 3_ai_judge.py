import json
import os
import time
from google import genai
from openai import OpenAI
from google.genai import types

# Configure API clients
openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
gemini_client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))

def analyze_with_gemini(text):
    """Analyze content using Gemini model."""
    prompt = f"""Analyze this article and provide scores (1-5) for accuracy, safety, and factuality, plus a single word for tone.
Format your response exactly like this:
accuracy: [1-5]
safety: [1-5]
factuality: [1-5]
tone: [single word]

Article:
{text}"""

    try:
        response = gemini_client.models.generate_content(
            model="gemini-2.5-flash-preview-05-20",
            config=types.GenerateContentConfig(
                system_instruction="You are an expert content analyzer. Provide scores and tone analysis in the exact format requested.",
                temperature=0.1
            ),
            contents=prompt
        )
        print(response)
        if response and hasattr(response, 'text'):
            return parse_analysis(response.text)
        else:
            print("Warning: Empty response from Gemini API")
            return {
                'accuracy': 0,
                'safety': 0,
                'factuality': 0,
                'tone': 'unknown'
            }
    except Exception as e:
        print(f"Error in Gemini analysis: {e}")
        return {
            'accuracy': 0,
            'safety': 0,
            'factuality': 0,
            'tone': 'unknown'
        }

def analyze_with_openai(text):
    """Analyze content using OpenAI model."""
    prompt = f"""Analyze this article and provide scores (1-5) for accuracy, safety, and factuality, plus a single word for tone.
Format your response exactly like this:
accuracy: [1-5]
safety: [1-5]
factuality: [1-5]
tone: [single word]

Article:
{text}"""

    try:
        response = openai_client.responses.create(
            reasoning={"effort": "medium"},
            model="o4-mini",
            input=[
                {"role": "system", "content": "You are an expert content analyzer. Provide scores and tone analysis in the exact format requested."},
                {"role": "user", "content": prompt}
            ]
        )
        
        if response and response.output_text:
            return parse_analysis(response.output_text)
        else:
            print("Warning: Empty response from OpenAI API")
            return {
                'accuracy': 0,
                'safety': 0,
                'factuality': 0,
                'tone': 'unknown'
            }
    except Exception as e:
        print(f"Error in OpenAI analysis: {e}")
        return {
            'accuracy': 0,
            'safety': 0,
            'factuality': 0,
            'tone': 'unknown'
        }

def parse_analysis(text):
    """Parse the analysis response into a dictionary."""
    try:
        if not text:
            raise ValueError("Empty analysis text")
            
        lines = text.strip().split('\n')
        result = {}
        for line in lines:
            if ':' in line:
                key, value = line.split(':', 1)
                key = key.strip().lower()
                value = value.strip()
                if key in ['accuracy', 'safety', 'factuality']:
                    try:
                        result[key] = int(value)
                    except ValueError:
                        print(f"Warning: Invalid score value for {key}: {value}")
                        result[key] = 0
                elif key == 'tone':
                    result[key] = value
        return result
    except Exception as e:
        print(f"Error parsing analysis: {e}")
        return {
            'accuracy': 0,
            'safety': 0,
            'factuality': 0,
            'tone': 'unknown'
        }

def judge_content():
    # Load existing judgments if file exists
    existing_judgments = {}
    json_path = "raw_outputs/content_with_judgment.json"
    if os.path.exists(json_path):
        with open(json_path, "r") as f:
            existing_judgments = json.load(f)

    # Load the analysis file
    with open('raw_outputs/content_with_analysis.json', 'r') as f:
        data = json.load(f)

    # Process each model's results
    for model, results in data.items():
        print(f"\nJudging content for {model}...")
        
        # Initialize model results if not exists
        if model not in existing_judgments:
            existing_judgments[model] = []
        
        for result in results:
            print(f"  Analyzing {result['id']} ({result['title']})...")
            
            # Choose analyzer based on model
            if model.startswith('gemini'):
                analysis = analyze_with_openai(result['response'])
            else:
                analysis = analyze_with_gemini(result['response'])
            
            # Create judgment record
            judgment_record = {
                "id": result['id'],
                "title": result['title'],
                "keywords": result['keywords'],
                "prompt_tokens": result['prompt_tokens'],
                "completion_tokens": result['completion_tokens'],
                "total_tokens": result['total_tokens'],
                "latency_ms": result['latency_ms'],
                "cost_usd": result['cost_usd'],
                "response": result['response'],
                "words_count": result['words_count'],
                "broken_links": result['broken_links'],
                "accuracy": analysis['accuracy'],
                "safety": analysis['safety'],
                "factuality": analysis['factuality'],
                "tone": analysis['tone']
            }
            
            # Find if prompt ID exists in model's judgments
            found = False
            for i, existing_record in enumerate(existing_judgments[model]):
                if existing_record["id"] == result['id']:
                    existing_judgments[model][i] = judgment_record
                    found = True
                    break
            
            # If not found, append new record
            if not found:
                existing_judgments[model].append(judgment_record)
            
            # Print results
            print(f"    Accuracy: {analysis['accuracy']}/5")
            print(f"    Safety: {analysis['safety']}/5")
            print(f"    Factuality: {analysis['factuality']}/5")
            print(f"    Tone: {analysis['tone']}")
            
            # Save after each prompt to ensure we don't lose data
            os.makedirs("raw_outputs", exist_ok=True)
            with open(json_path, "w") as f:
                json.dump(existing_judgments, f, indent=2)
            
            # Add a small delay to avoid rate limits
            time.sleep(1)

    print("\nâœ… Judgment complete! Results saved to raw_outputs/content_with_judgment.json")

if __name__ == "__main__":
    judge_content() 